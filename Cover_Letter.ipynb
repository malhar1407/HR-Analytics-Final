{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L12-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sent_tokenize \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "from nltk.tokenize import sent_tokenize \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt') \n",
    "import PyPDF2 as pdf\n",
    "from PyPDF2 import PdfReader, PdfWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"C:\\Users\\malhar.shinde\\Downloads\\braintree.pdf\",\"rb\")\n",
    "reader = PdfReader(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = reader.getNumPages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for page_num in range(length):\n",
    "    text += reader.pages[page_num].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_letter = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords =\"\"\"My work adds business value to customers.\n",
    "             My work adds career value to fellow employees.\n",
    "             My work adds social value to communities.\n",
    "             My work shows my integrity.\n",
    "             My work shows my team work and team spirit.\n",
    "             My work shows my trustworthy quality.\n",
    "             My work showcased digital transformation. \n",
    "             My work shows my simplicity. \n",
    "             My work shows my entrepreneurial spirit. \n",
    "             I have good communication skills. \n",
    "             I have good interpersonal skills. \n",
    "             My work shows innovation. \n",
    "             My work shows resilience. \n",
    "             I am confident about my work. \n",
    "             I have leadership qualities. \n",
    "             My work always meets deadlines.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(sentence):\n",
    "    # Removing URLS\n",
    "    sentence = re.sub(r\"https?://\\S+|www\\.\\S+\",\" \",sentence)\n",
    "    \n",
    "    # Removing html tags\n",
    "    sentence = re.sub(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\",\" \",sentence)\n",
    "    \n",
    "    # Cleaning white spaces\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
    "\n",
    "    # Cleaning .com\n",
    "    sentence = re.sub(r\"\\.com\",\" \",sentence)\n",
    "        \n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    #Removing Stop Words\n",
    "    tokens = \"\"\n",
    "    for token in sentence.split():\n",
    "        if token not in stop_words:\n",
    "            tokens=tokens+\" \"+token\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_cover_letter = clean_text(cover_letter)\n",
    "clean_keywords = clean_text(keywords)\n",
    "tokenize_cover_letter = sent_tokenize(clean_cover_letter)\n",
    "tokenize_keywords = sent_tokenize(clean_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' february 2017 dear braintree, letter express interest posting pm intern role.', 'i’m currently pursuing masters computer science cornell tech new york city, received bachelor’s computer science prior.', 'i’m interested braintree value secure payment systems everyday life recognize upcoming generations appreciate streamlined purchasing process braintree helps provide.', 'past projects, received good feedback work done using sketch keynote rapid prototyping presentation designs.', 'background includes internships involving web design development using html/css/js well optimizing ui unity applications.', 'internship, hope gain start pm career.', 'since experience product design already, took initiative past fall attending part-time product management course new york city product school.', '20, one youngest students accepted given experience, decided admit me.', 'eventually, would like earn full-time position ebay internship.', 'feel free refer web portfolio speaker deck examples product presentation work.', 'sincerely, frances coronel personal website fvcproductions linkedin linkedin /in/fvcproductions github github /fvcproductions speaker deck speakerdeck /fvcproductions']\n",
      "[' work adds business value customers.', 'work adds career value fellow employees.', 'work adds social value communities.', 'work shows integrity.', 'work shows team work team spirit.', 'work shows trustworthy quality.', 'work showcased digital transformation.', 'work shows simplicity.', 'work shows entrepreneurial spirit.', 'good communication skills.', 'good interpersonal skills.', 'work shows innovation.', 'work shows resilience.', 'confident work.', 'leadership qualities.', 'work always meets deadlines.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_cover_letter)\n",
    "print(tokenize_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding using Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_cover_letter = model.encode(tokenize_cover_letter)\n",
    "embeddings_keywords = model.encode(tokenize_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = util.cos_sim(embeddings_cover_letter,embeddings_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values_column = torch.max(cos_sim, dim = 0)\n",
    "min_value = torch.min(cos_sim)\n",
    "max_value = torch.max(cos_sim)\n",
    "max_values = max_values_column.values\n",
    "cosine_similarity_score = torch.mean(max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3290)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "After trying out different ways it can be concluded that the most accurate results are obtained by cleaning the text first and then embedding the sentences. Then we can find the most accurate results from cosine similarity.\n",
    "\n",
    "If the results are greater than 0.40 to 0.42 that means that the candidate is a good cultural fit for the organization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
