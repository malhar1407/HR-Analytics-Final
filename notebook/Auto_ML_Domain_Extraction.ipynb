{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "resume_data = pd.read_csv(r'D:\\HR-Analytics-Final\\notebook\\undersampled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)\n",
    "    text = re.sub(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\", \" \", text)\n",
    "    text = re.sub(r\"\\b(?:\\d{3}[-.\\s]??\\d{3}[-.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-.\\s]??\\d{4}|\\d{3}[-.\\s]??\\d{4})\\b\", \" \", text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data['preprocessed_text'] = resume_data['Resume'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "resume_data['Category_encoded'] = label_encoder.fit_transform(resume_data['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    resume_data['preprocessed_text'], \n",
    "    resume_data['Category_encoded'], \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=resume_data['Category_encoded']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for each classifier\n",
    "rf_params = {\n",
    "    'clf__n_estimators': [50, 100, 200],\n",
    "    'clf__max_depth': [None, 10, 20],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__gamma': ['scale', 'auto'],\n",
    "    'clf__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "nb_params = {\n",
    "    'clf__alpha': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "logreg_params = {\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "gb_params = {\n",
    "    'clf__learning_rate': [0.1, 0.05, 0.01],\n",
    "    'clf__max_depth': [3, 5, 10],\n",
    "    'clf__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "nn_params = {\n",
    "    'clf__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'clf__activation': ['relu', 'logistic', 'tanh', 'softmax'],\n",
    "    'clf__solver': ['adam', 'sgd'],  # 'adam' often works well for large datasets, 'sgd' for smaller datasets\n",
    "    'clf__alpha': [0.0001, 0.001, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier pipelines with TF-IDF vectorizer\n",
    "classifier_pipelines = {\n",
    "    'Random Forest': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', SVC(random_state=42))\n",
    "    ]),\n",
    "    'Multinomial Naive Bayes': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', MultinomialNB())\n",
    "    ]),\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', LogisticRegression(random_state=42))\n",
    "    ]),\n",
    "    'Neural Network': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('scaler', StandardScaler(with_mean=False)),\n",
    "        ('clf', MLPClassifier(random_state=42))\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest\n",
      "Best parameters: {'clf__max_depth': 20, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.9903902964584854\n",
      "Test loss: 0.5800176092115225\n",
      "Test accuracy: 1.0\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      1.00      1.00         4\n",
      "                     Arts       1.00      1.00      1.00         4\n",
      "       Automation Testing       1.00      1.00      1.00         4\n",
      "               Blockchain       1.00      1.00      1.00         4\n",
      "         Business Analyst       1.00      1.00      1.00         4\n",
      "           Civil Engineer       1.00      1.00      1.00         4\n",
      "             Data Analyst       1.00      1.00      1.00         4\n",
      "             Data Science       1.00      1.00      1.00         4\n",
      "                 Database       1.00      1.00      1.00         4\n",
      "          DevOps Engineer       1.00      1.00      1.00         4\n",
      "         DotNet Developer       1.00      1.00      1.00         4\n",
      "            ETL Developer       1.00      1.00      1.00         4\n",
      "   Electrical Engineering       1.00      1.00      1.00         4\n",
      "                       HR       1.00      1.00      1.00         4\n",
      "                   Hadoop       1.00      1.00      1.00         4\n",
      "       Health and fitness       1.00      1.00      1.00         4\n",
      "           Java Developer       1.00      1.00      1.00         4\n",
      "      Mechanical Engineer       1.00      1.00      1.00         4\n",
      "Network Security Engineer       1.00      1.00      1.00         4\n",
      "       Operations Manager       1.00      1.00      1.00         4\n",
      "                      PMO       1.00      1.00      1.00         4\n",
      "         Python Developer       1.00      1.00      1.00         4\n",
      "            SAP Developer       1.00      1.00      1.00         4\n",
      "                    Sales       1.00      1.00      1.00         4\n",
      "                  Testing       1.00      1.00      1.00         4\n",
      "            Web Designing       1.00      1.00      1.00         4\n",
      "\n",
      "                 accuracy                           1.00       104\n",
      "                macro avg       1.00      1.00      1.00       104\n",
      "             weighted avg       1.00      1.00      1.00       104\n",
      "\n",
      "\n",
      "\n",
      "Training SVM\n",
      "Best parameters: {'clf__C': 10, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}\n",
      "Best cross-validation accuracy: 0.9855767559865152\n",
      "Test accuracy: 0.9903846153846154\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      1.00      1.00         4\n",
      "                     Arts       1.00      1.00      1.00         4\n",
      "       Automation Testing       1.00      1.00      1.00         4\n",
      "               Blockchain       1.00      1.00      1.00         4\n",
      "         Business Analyst       1.00      1.00      1.00         4\n",
      "           Civil Engineer       1.00      1.00      1.00         4\n",
      "             Data Analyst       1.00      1.00      1.00         4\n",
      "             Data Science       0.80      1.00      0.89         4\n",
      "                 Database       1.00      0.75      0.86         4\n",
      "          DevOps Engineer       1.00      1.00      1.00         4\n",
      "         DotNet Developer       1.00      1.00      1.00         4\n",
      "            ETL Developer       1.00      1.00      1.00         4\n",
      "   Electrical Engineering       1.00      1.00      1.00         4\n",
      "                       HR       1.00      1.00      1.00         4\n",
      "                   Hadoop       1.00      1.00      1.00         4\n",
      "       Health and fitness       1.00      1.00      1.00         4\n",
      "           Java Developer       1.00      1.00      1.00         4\n",
      "      Mechanical Engineer       1.00      1.00      1.00         4\n",
      "Network Security Engineer       1.00      1.00      1.00         4\n",
      "       Operations Manager       1.00      1.00      1.00         4\n",
      "                      PMO       1.00      1.00      1.00         4\n",
      "         Python Developer       1.00      1.00      1.00         4\n",
      "            SAP Developer       1.00      1.00      1.00         4\n",
      "                    Sales       1.00      1.00      1.00         4\n",
      "                  Testing       1.00      1.00      1.00         4\n",
      "            Web Designing       1.00      1.00      1.00         4\n",
      "\n",
      "                 accuracy                           0.99       104\n",
      "                macro avg       0.99      0.99      0.99       104\n",
      "             weighted avg       0.99      0.99      0.99       104\n",
      "\n",
      "\n",
      "\n",
      "Training Multinomial Naive Bayes\n",
      "Best parameters: {'clf__alpha': 0.1}\n",
      "Best cross-validation accuracy: 0.9687554304382581\n",
      "Test loss: 0.07186026848159627\n",
      "Test accuracy: 0.9903846153846154\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      1.00      1.00         4\n",
      "                     Arts       1.00      1.00      1.00         4\n",
      "       Automation Testing       1.00      1.00      1.00         4\n",
      "               Blockchain       1.00      1.00      1.00         4\n",
      "         Business Analyst       1.00      1.00      1.00         4\n",
      "           Civil Engineer       1.00      1.00      1.00         4\n",
      "             Data Analyst       1.00      1.00      1.00         4\n",
      "             Data Science       1.00      1.00      1.00         4\n",
      "                 Database       1.00      1.00      1.00         4\n",
      "          DevOps Engineer       1.00      1.00      1.00         4\n",
      "         DotNet Developer       1.00      1.00      1.00         4\n",
      "            ETL Developer       1.00      1.00      1.00         4\n",
      "   Electrical Engineering       1.00      1.00      1.00         4\n",
      "                       HR       1.00      1.00      1.00         4\n",
      "                   Hadoop       1.00      1.00      1.00         4\n",
      "       Health and fitness       1.00      1.00      1.00         4\n",
      "           Java Developer       1.00      1.00      1.00         4\n",
      "      Mechanical Engineer       1.00      0.75      0.86         4\n",
      "Network Security Engineer       1.00      1.00      1.00         4\n",
      "       Operations Manager       0.80      1.00      0.89         4\n",
      "                      PMO       1.00      1.00      1.00         4\n",
      "         Python Developer       1.00      1.00      1.00         4\n",
      "            SAP Developer       1.00      1.00      1.00         4\n",
      "                    Sales       1.00      1.00      1.00         4\n",
      "                  Testing       1.00      1.00      1.00         4\n",
      "            Web Designing       1.00      1.00      1.00         4\n",
      "\n",
      "                 accuracy                           0.99       104\n",
      "                macro avg       0.99      0.99      0.99       104\n",
      "             weighted avg       0.99      0.99      0.99       104\n",
      "\n",
      "\n",
      "\n",
      "Training Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "9 fits failed out of a total of 18.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.9182567         nan 0.97836513        nan 0.98317867]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__C': 10, 'clf__penalty': 'l2'}\n",
      "Best cross-validation accuracy: 0.983178674451743\n",
      "Test loss: 0.2357708639841659\n",
      "Test accuracy: 0.9903846153846154\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      1.00      1.00         4\n",
      "                     Arts       1.00      1.00      1.00         4\n",
      "       Automation Testing       1.00      1.00      1.00         4\n",
      "               Blockchain       1.00      1.00      1.00         4\n",
      "         Business Analyst       1.00      1.00      1.00         4\n",
      "           Civil Engineer       1.00      1.00      1.00         4\n",
      "             Data Analyst       1.00      1.00      1.00         4\n",
      "             Data Science       0.80      1.00      0.89         4\n",
      "                 Database       1.00      0.75      0.86         4\n",
      "          DevOps Engineer       1.00      1.00      1.00         4\n",
      "         DotNet Developer       1.00      1.00      1.00         4\n",
      "            ETL Developer       1.00      1.00      1.00         4\n",
      "   Electrical Engineering       1.00      1.00      1.00         4\n",
      "                       HR       1.00      1.00      1.00         4\n",
      "                   Hadoop       1.00      1.00      1.00         4\n",
      "       Health and fitness       1.00      1.00      1.00         4\n",
      "           Java Developer       1.00      1.00      1.00         4\n",
      "      Mechanical Engineer       1.00      1.00      1.00         4\n",
      "Network Security Engineer       1.00      1.00      1.00         4\n",
      "       Operations Manager       1.00      1.00      1.00         4\n",
      "                      PMO       1.00      1.00      1.00         4\n",
      "         Python Developer       1.00      1.00      1.00         4\n",
      "            SAP Developer       1.00      1.00      1.00         4\n",
      "                    Sales       1.00      1.00      1.00         4\n",
      "                  Testing       1.00      1.00      1.00         4\n",
      "            Web Designing       1.00      1.00      1.00         4\n",
      "\n",
      "                 accuracy                           0.99       104\n",
      "                macro avg       0.99      0.99      0.99       104\n",
      "             weighted avg       0.99      0.99      0.99       104\n",
      "\n",
      "\n",
      "\n",
      "Training Neural Network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "54 fits failed out of a total of 216.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 747, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'identity', 'relu', 'tanh', 'logistic'}. Got 'softmax' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 747, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'tanh', 'relu', 'identity', 'logistic'}. Got 'softmax' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 747, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'tanh', 'logistic', 'relu', 'identity'}. Got 'softmax' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 747, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'logistic', 'identity', 'tanh', 'relu'}. Got 'softmax' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 747, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'logistic', 'relu', 'tanh', 'identity'}. Got 'softmax' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 747, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'tanh', 'identity', 'logistic', 'relu'}. Got 'softmax' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\parth.parikh1\\AppData\\Local\\anaconda3\\envs\\hrenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.90614465 0.8893407  0.89415424 0.86530775 0.91580649 0.894189\n",
      " 0.91337365 0.8893407  0.89655232 0.86530775 0.90621416 0.894189\n",
      " 0.90857749 0.8893407  0.89415424 0.86530775 0.90861224 0.894189\n",
      " 0.92538143 0.90612727 0.92777952 0.90857749 0.92777952 0.33654815\n",
      " 0.92538143 0.90612727 0.92777952 0.90857749 0.9301776  0.33654815\n",
      " 0.92538143 0.90612727 0.94222014 0.90857749 0.93500851 0.33654815\n",
      " 0.91337365 0.88696    0.90372919 0.88216383 0.89893303 0.86049421\n",
      " 0.91337365 0.88696    0.90856011 0.88216383 0.90136586 0.86049421\n",
      " 0.91337365 0.88696    0.91339103 0.88216383 0.90136586 0.86049421\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__activation': 'logistic', 'clf__alpha': 0.01, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'adam'}\n",
      "Best cross-validation accuracy: 0.9422201369339311\n",
      "Test loss: 0.09968510223376012\n",
      "Test accuracy: 0.9903846153846154\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      1.00      1.00         4\n",
      "                     Arts       1.00      1.00      1.00         4\n",
      "       Automation Testing       1.00      1.00      1.00         4\n",
      "               Blockchain       1.00      1.00      1.00         4\n",
      "         Business Analyst       1.00      1.00      1.00         4\n",
      "           Civil Engineer       1.00      1.00      1.00         4\n",
      "             Data Analyst       1.00      1.00      1.00         4\n",
      "             Data Science       0.80      1.00      0.89         4\n",
      "                 Database       1.00      0.75      0.86         4\n",
      "          DevOps Engineer       1.00      1.00      1.00         4\n",
      "         DotNet Developer       1.00      1.00      1.00         4\n",
      "            ETL Developer       1.00      1.00      1.00         4\n",
      "   Electrical Engineering       1.00      1.00      1.00         4\n",
      "                       HR       1.00      1.00      1.00         4\n",
      "                   Hadoop       1.00      1.00      1.00         4\n",
      "       Health and fitness       1.00      1.00      1.00         4\n",
      "           Java Developer       1.00      1.00      1.00         4\n",
      "      Mechanical Engineer       1.00      1.00      1.00         4\n",
      "Network Security Engineer       1.00      1.00      1.00         4\n",
      "       Operations Manager       1.00      1.00      1.00         4\n",
      "                      PMO       1.00      1.00      1.00         4\n",
      "         Python Developer       1.00      1.00      1.00         4\n",
      "            SAP Developer       1.00      1.00      1.00         4\n",
      "                    Sales       1.00      1.00      1.00         4\n",
      "                  Testing       1.00      1.00      1.00         4\n",
      "            Web Designing       1.00      1.00      1.00         4\n",
      "\n",
      "                 accuracy                           0.99       104\n",
      "                macro avg       0.99      0.99      0.99       104\n",
      "             weighted avg       0.99      0.99      0.99       104\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Perform grid search cross-validation for each classifier\n",
    "for name, pipeline in classifier_pipelines.items():\n",
    "    print(\"Training\", name)\n",
    "    if name == 'SVM':\n",
    "        grid_search = GridSearchCV(pipeline, svm_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    elif name == 'Random Forest':\n",
    "        grid_search = GridSearchCV(pipeline, rf_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    elif name == 'Multinomial Naive Bayes':\n",
    "        grid_search = GridSearchCV(pipeline, nb_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    elif name == 'Logistic Regression':\n",
    "        grid_search = GridSearchCV(pipeline, logreg_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    elif name == 'Neural Network':\n",
    "        grid_search = GridSearchCV(pipeline, nn_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Calculate loss on the test set\n",
    "    if hasattr(grid_search.best_estimator_, 'predict_proba'):\n",
    "        y_pred_proba = grid_search.predict_proba(X_test)\n",
    "        loss = log_loss(y_test, y_pred_proba)\n",
    "        print(\"Test loss:\", loss)\n",
    "\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume</th>\n",
       "      <th>Category</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>Category_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TECHNICAL QUALIFICATIONS: â?¢ Windows, Ms. Off...</td>\n",
       "      <td>Advocate</td>\n",
       "      <td>technical qualification window m officeeducati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Education Details \\n B.Com, LL.B.,   Universit...</td>\n",
       "      <td>Advocate</td>\n",
       "      <td>education detail bcom llb university clacutta ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Education Details \\n LLB.   Dibrugarh Universi...</td>\n",
       "      <td>Advocate</td>\n",
       "      <td>education detail llb dibrugarh university advo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Education Details \\nNovember 2016 to January 2...</td>\n",
       "      <td>Advocate</td>\n",
       "      <td>education detail november january llm master l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKILLS â?¢ Knows English as native speaker (IE...</td>\n",
       "      <td>Advocate</td>\n",
       "      <td>skill know english native speaker ielts overal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Resume  Category  \\\n",
       "0  TECHNICAL QUALIFICATIONS: â?¢ Windows, Ms. Off...  Advocate   \n",
       "1  Education Details \\n B.Com, LL.B.,   Universit...  Advocate   \n",
       "2  Education Details \\n LLB.   Dibrugarh Universi...  Advocate   \n",
       "3  Education Details \\nNovember 2016 to January 2...  Advocate   \n",
       "4  SKILLS â?¢ Knows English as native speaker (IE...  Advocate   \n",
       "\n",
       "                                   preprocessed_text  Category_encoded  \n",
       "0  technical qualification window m officeeducati...                 0  \n",
       "1  education detail bcom llb university clacutta ...                 0  \n",
       "2  education detail llb dibrugarh university advo...                 0  \n",
       "3  education detail november january llm master l...                 0  \n",
       "4  skill know english native speaker ielts overal...                 0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler(with_mean=False)),\n",
      "                ('clf',\n",
      "                 MLPClassifier(activation='logistic', alpha=0.01,\n",
      "                               random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Define the pipeline with the best parameters for the Neural Network\n",
    "best_nn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', solver='adam', alpha=0.01, random_state=42))\n",
    "])\n",
    "\n",
    "# Print the pipeline\n",
    "print(best_nn_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_nn_pipeline.pkl']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save the pipeline with the best parameters\n",
    "joblib.dump(best_nn_pipeline, 'best_nn_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model with 0.099 loss and 0.99 ccuracy is Neural Network with Multilayer Percepton and parameters as \n",
    "Best parameters: {'clf__activation': 'logistic', 'clf__alpha': 0.01, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_final.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the label encoder object to a file\n",
    "joblib.dump(label_encoder, 'label_encoder_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer_final.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "# Fit the TF-IDF vectorizer with your training data\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "# Save the fitted TF-IDF vectorizer to a file\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler(with_mean=False)),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.01,\n",
       "                               random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler(with_mean=False)),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.01,\n",
       "                               random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler(with_mean=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.01, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('scaler', StandardScaler(with_mean=False)),\n",
       "                ('clf',\n",
       "                 MLPClassifier(activation='logistic', alpha=0.01,\n",
       "                               random_state=42))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Define the StandardScaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "# Define the MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', solver='adam', alpha=0.01, random_state=42)\n",
    "\n",
    "# Define the pipeline with the TF-IDF vectorizer, StandardScaler, and MLPClassifier\n",
    "best_nn_pipeline = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('scaler', scaler),\n",
    "    ('clf', mlp_classifier)\n",
    "])\n",
    "\n",
    "# Fit the pipeline with training data\n",
    "best_nn_pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_nn_pipeline.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the pipeline with the best parameters\n",
    "joblib.dump(best_nn_pipeline, 'best_nn_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB(alpha=0.1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB(alpha=0.1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf', MultinomialNB(alpha=0.1))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Define the Multinomial Naive Bayes classifier with the best parameters\n",
    "best_nb_classifier = MultinomialNB(alpha=0.1)\n",
    "\n",
    "# Define the pipeline with the TF-IDF vectorizer and Multinomial Naive Bayes classifier\n",
    "best_nb_pipeline = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('clf', best_nb_classifier)\n",
    "])\n",
    "\n",
    "# Fit the pipeline with training data\n",
    "best_nb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_nb_pipeline.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained pipeline with the best parameters\n",
    "joblib.dump(best_nb_pipeline, 'best_nb_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
